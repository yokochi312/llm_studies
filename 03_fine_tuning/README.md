# 03. ファインチューニング

このセクションでは、既存の学習済み言語モデルを特定のタスクに適応させる「ファインチューニング」について学びます。

## 学習内容

1.  **基本的なファインチューニング**:
    - Hugging Faceの`Trainer` APIを利用して、日本語BERTモデルをテキスト分類タスクでファインチューニングする基本的なプロセスを実装します。
    - データセットには「livedoorニュースコーパス」を使用します。

2.  **効率的なファインチューニング (PEFT/LoRA)**:
    - パラメータ効率の良いファインチューニング手法であるPEFT（Parameter-Efficient Fine-Tuning）とその一種であるLoRA（Low-Rank Adaptation）について学びます。
    - LoRAを用いて、より少ない計算リソースで効率的にモデルをファインチューニングする方法を実践します。

これらの演習を通して、独自のデータで言語モデルの性能を最大限に引き出すための実践的なスキルを習得します。 